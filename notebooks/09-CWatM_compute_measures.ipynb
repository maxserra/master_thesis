{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute measures of dependence on CWatM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import src.visualization.visualize as visualize\n",
    "import src.data.utils as utils\n",
    "from src.dependence_measures.compare import compute_bivariate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_FOLDER_PATH = Path(\"../data/processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_land_df = pd.read_parquet(PROCESSED_DATA_FOLDER_PATH.joinpath(\"CWatM_data\", \"all_land.parquet\"))\n",
    "forcings_land_df = pd.read_parquet(PROCESSED_DATA_FOLDER_PATH.joinpath(\"CWatM_data\", \"forcings_land.parquet\"))\n",
    "outputs_land_df = pd.read_parquet(PROCESSED_DATA_FOLDER_PATH.joinpath(\"CWatM_data\", \"outputs_land.parquet\"))\n",
    "\n",
    "data_df = pd.concat((all_land_df, forcings_land_df, outputs_land_df), axis=1)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_COLUMNS = list(all_land_df.columns)\n",
    "#     \"porosity\",\n",
    "#     \"firstStorDepth\",\n",
    "#     \"percolationImp\",\n",
    "#     \"tanslope\",\n",
    "#     \"maxRootDepth_forest\",\n",
    "#     \"maxRootDepth_grassland\"\n",
    "# ]\n",
    "FORCINGS_COLUMNS = list(forcings_land_df.columns)\n",
    "#     \"pr\",\n",
    "#     \"tas\",\n",
    "#     \"tasmax\",\n",
    "#     \"tasmin\",\n",
    "#     \"ps\",\n",
    "#     \"rlds\",\n",
    "#     \"rsds\",\n",
    "#     \"sfcwind\",\n",
    "#     \"hurs\",\n",
    "#     \"huss\",\n",
    "# ]\n",
    "OUTPUTS_COLUMNS = list(outputs_land_df.columns)\n",
    "#     \"evap-total\",\n",
    "#     \"potevap\",\n",
    "#     \"qr\",\n",
    "#     \"qtot\"\n",
    "# ]\n",
    "\n",
    "# data_df = data_df.iloc[:1000]\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute measures - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for inputs_columns_split in np.array_split(INPUTS_COLUMNS, len(INPUTS_COLUMNS)):\n",
    "\n",
    "    for forcings_columns_split in np.array_split(FORCINGS_COLUMNS, 4):\n",
    "\n",
    "        input_cols = inputs_columns_split.tolist() + forcings_columns_split.tolist()\n",
    "\n",
    "        scores_df = compute_bivariate_scores(data_df,\n",
    "                                             input_cols=input_cols,\n",
    "                                             output_cols=OUTPUTS_COLUMNS,\n",
    "                                             dst_file_path=PROCESSED_DATA_FOLDER_PATH.joinpath(\"bivariate_metrics\", \"CWatM\", \"measures_global.csv\"),\n",
    "                                             return_all=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute measures of shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OF_SHUFFLES = 20\n",
    "\n",
    "for shuffled_id in range(N_OF_SHUFFLES):\n",
    "    shuffled_data_df = utils.shuffle_data(data_df)\n",
    "\n",
    "    for inputs_columns_split in np.array_split(INPUTS_COLUMNS, len(INPUTS_COLUMNS)):\n",
    "\n",
    "        for forcings_columns_split in np.array_split(FORCINGS_COLUMNS, 4):\n",
    "\n",
    "            input_cols = inputs_columns_split.tolist() + forcings_columns_split.tolist()\n",
    "\n",
    "            shuffled_scores_df = compute_bivariate_scores(shuffled_data_df,\n",
    "                                                          input_cols=input_cols,\n",
    "                                                          output_cols=OUTPUTS_COLUMNS,\n",
    "                                                          dst_file_path=PROCESSED_DATA_FOLDER_PATH.joinpath(\"bivariate_metrics\",\n",
    "                                                                                                            \"CWatM\",\n",
    "                                                                                                            \"shuffled\",\n",
    "                                                                                                            f\"measures_global-{shuffled_id}.csv\"),\n",
    "                                                          return_all=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute measures - Gnann regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER_PATH = Path(\"../data/raw\")\n",
    "\n",
    "domains_df = pd.read_csv(RAW_DATA_FOLDER_PATH.joinpath(\"ISIMIP_2b_aggregated_variables\", \"domains.csv\"))\n",
    "domains_df = domains_df[[\"lon\", \"lat\", \"domain_days_below_1_0.08_aridity_netrad\"]]\n",
    "regions_df = domains_df.rename(columns={\"domain_days_below_1_0.08_aridity_netrad\": \"region\"})\n",
    "regions_df = regions_df.set_index([\"lon\", \"lat\"])\n",
    "\n",
    "regions = regions_df[\"region\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "\n",
    "    region_indices = regions_df[regions_df[\"region\"] == region].index\n",
    "    region_indices = set(region_indices).intersection(data_df.index)\n",
    "\n",
    "    print(region, len(region_indices))\n",
    "\n",
    "    region_data_df = data_df.loc[list(region_indices)]\n",
    "\n",
    "    for inputs_columns_split in np.array_split(INPUTS_COLUMNS, 25):\n",
    "\n",
    "        for forcings_columns_split in np.array_split(FORCINGS_COLUMNS, 2):\n",
    "\n",
    "            input_cols = inputs_columns_split.tolist() + forcings_columns_split.tolist()\n",
    "\n",
    "            scores_df = compute_bivariate_scores(region_data_df,\n",
    "                                                 input_cols=input_cols,\n",
    "                                                 output_cols=OUTPUTS_COLUMNS,\n",
    "                                                 dst_file_path=PROCESSED_DATA_FOLDER_PATH.joinpath(\"bivariate_metrics\",\n",
    "                                                                                                   \"CWatM\",\n",
    "                                                                                                   f\"measures_{region}.csv\"),\n",
    "                                                 return_all=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute measures of shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shuffled_scores_region(data_df,\n",
    "                                   regions_df,\n",
    "                                   region,\n",
    "                                   n_shuffles: int):\n",
    "\n",
    "    region_indices = regions_df[regions_df[\"region\"] == region].index\n",
    "    region_indices = set(region_indices).intersection(data_df.index)\n",
    "\n",
    "    region_data_df = data_df.loc[list(region_indices)]\n",
    "\n",
    "    for shuffled_id in range(n_shuffles):\n",
    "        shuffled_region_data_df = utils.shuffle_data(region_data_df)\n",
    "\n",
    "        for inputs_columns_split in np.array_split(INPUTS_COLUMNS, 25):\n",
    "\n",
    "            for forcings_columns_split in np.array_split(FORCINGS_COLUMNS, 2):\n",
    "\n",
    "                input_cols = inputs_columns_split.tolist() + forcings_columns_split.tolist()\n",
    "\n",
    "                shuffled_scores_df = compute_bivariate_scores(shuffled_region_data_df,\n",
    "                                                             input_cols=input_cols,\n",
    "                                                             output_cols=OUTPUTS_COLUMNS,\n",
    "                                                             dst_file_path=PROCESSED_DATA_FOLDER_PATH.joinpath(\"bivariate_metrics\",\n",
    "                                                                                                               \"CWatM\",\n",
    "                                                                                                               \"shuffled\",\n",
    "                                                                                                               f\"measures_{region}-{shuffled_id}.csv\"),\n",
    "                                                             return_all=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"wet warm\"\n",
    "N_OF_SHUFFLES = 20\n",
    "\n",
    "compute_shuffled_scores_region(data_df=data_df,\n",
    "                               regions_df=regions_df,\n",
    "                               region=REGION,\n",
    "                               n_shuffles=N_OF_SHUFFLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"dry warm\"\n",
    "N_OF_SHUFFLES = 20\n",
    "\n",
    "compute_shuffled_scores_region(data_df=data_df,\n",
    "                               regions_df=regions_df,\n",
    "                               region=REGION,\n",
    "                               n_shuffles=N_OF_SHUFFLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"dry cold\"\n",
    "N_OF_SHUFFLES = 20\n",
    "\n",
    "compute_shuffled_scores_region(data_df=data_df,\n",
    "                               regions_df=regions_df,\n",
    "                               region=REGION,\n",
    "                               n_shuffles=N_OF_SHUFFLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"wet cold\"\n",
    "N_OF_SHUFFLES = 20\n",
    "\n",
    "compute_shuffled_scores_region(data_df=data_df,\n",
    "                               regions_df=regions_df,\n",
    "                               region=REGION,\n",
    "                               n_shuffles=N_OF_SHUFFLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis-U6WNLqtN-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
