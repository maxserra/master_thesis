{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse measures of dependence from CWatM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src.data.cwatm_data as cwatm_data\n",
    "import src.visualization.visualize as visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWATM_MEASURES_FOLDER = Path(\"../data/processed\", \"bivariate_metrics\", \"CWatM\")\n",
    "\n",
    "REGIONS = [\"dry cold\", \"dry warm\", \"wet cold\", \"wet warm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df = pd.read_csv(CWATM_MEASURES_FOLDER.joinpath(\"measures_global.csv\"),\n",
    "                          index_col=[\"input\", \"output\"])\n",
    "measures_dc_df = pd.read_csv(CWATM_MEASURES_FOLDER.joinpath(\"measures_dry cold.csv\"),\n",
    "                          index_col=[\"input\", \"output\"])\n",
    "measures_dw_df = pd.read_csv(CWATM_MEASURES_FOLDER.joinpath(\"measures_dry warm.csv\"),\n",
    "                          index_col=[\"input\", \"output\"])\n",
    "measures_wc_df = pd.read_csv(CWATM_MEASURES_FOLDER.joinpath(\"measures_wet cold.csv\"),\n",
    "                          index_col=[\"input\", \"output\"])\n",
    "measures_ww_df = pd.read_csv(CWATM_MEASURES_FOLDER.joinpath(\"measures_wet warm.csv\"),\n",
    "                          index_col=[\"input\", \"output\"])\n",
    "\n",
    "measures_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process measures results\n",
    "\n",
    "This processing consists of:\n",
    "1. Dropping un-interesting variable pairs (either `NaN` pearson or `0` MIC)\n",
    "2. Selecting the relevant measures for this study:\n",
    "    - pearson\n",
    "    - spearman\n",
    "    - MIC\n",
    "    - MAS\n",
    "    - MEV\n",
    "3. Computing the rank for each measure\n",
    "4. Computing the p-value of the top scoring 10% of variable pairs (by MIC)\n",
    "    - Using the shuffled (permutated) measures\n",
    "\n",
    "With the above data as a basis. We will continue by:\n",
    "\n",
    "1. Using the Benjamini and Hochberg procedure to control FDR at `alpha = 0.05` (for MIC)\n",
    "2. On the statistically significant variable pairs:\n",
    "    - Computing the non-linearity score MIC - pearson^2\n",
    "\n",
    "Tables and visuals:\n",
    "- Table of the top scoring 10% variable pairs with the 5 measures and MIC-pearson^2. With rank and p-value.\n",
    "- (Pearson) correlation matrix of the 5 measures and MIC-pearson^2\n",
    "- Scatter plot of p-values and the Benjamini and Hochberg line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df = cwatm_data.process_measures_df(measures_df)\n",
    "measures_dc_df = cwatm_data.process_measures_df(measures_dc_df)\n",
    "measures_dw_df = cwatm_data.process_measures_df(measures_dw_df)\n",
    "measures_wc_df = cwatm_data.process_measures_df(measures_wc_df)\n",
    "measures_ww_df = cwatm_data.process_measures_df(measures_ww_df)\n",
    "\n",
    "measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_measures_df = cwatm_data.compute_ranks_df(measures_df)\n",
    "ranks_measures_dc_df = cwatm_data.compute_ranks_df(measures_dc_df)\n",
    "ranks_measures_dw_df = cwatm_data.compute_ranks_df(measures_dw_df)\n",
    "ranks_measures_wc_df = cwatm_data.compute_ranks_df(measures_wc_df)\n",
    "ranks_measures_ww_df = cwatm_data.compute_ranks_df(measures_ww_df)\n",
    "\n",
    "ranks_measures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_values_measures_df = cwatm_data.compute_p_values_complete(\n",
    "#     shuffled_data_path=CWATM_MEASURES_FOLDER.joinpath(\"shuffled\"),\n",
    "#     region=\"global\",\n",
    "#     actual_df=measures_df\n",
    "# )\n",
    "p_values_measures_dc_df = cwatm_data.compute_p_values_complete(\n",
    "    shuffled_data_path=CWATM_MEASURES_FOLDER.joinpath(\"shuffled\"),\n",
    "    region=\"dry cold\",\n",
    "    actual_df=measures_dc_df\n",
    ")\n",
    "p_values_measures_dw_df = cwatm_data.compute_p_values_complete(\n",
    "    shuffled_data_path=CWATM_MEASURES_FOLDER.joinpath(\"shuffled\"),\n",
    "    region=\"dry warm\",\n",
    "    actual_df=measures_dw_df\n",
    ")\n",
    "p_values_measures_wc_df = cwatm_data.compute_p_values_complete(\n",
    "    shuffled_data_path=CWATM_MEASURES_FOLDER.joinpath(\"shuffled\"),\n",
    "    region=\"wet cold\",\n",
    "    actual_df=measures_wc_df\n",
    ")\n",
    "p_values_measures_ww_df = cwatm_data.compute_p_values_complete(\n",
    "    shuffled_data_path=CWATM_MEASURES_FOLDER.joinpath(\"shuffled\"),\n",
    "    region=\"wet warm\",\n",
    "    actual_df=measures_ww_df\n",
    ")\n",
    "\n",
    "p_values_measures_ww_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant_p_values_series, benjamini_hochberg_data = cwatm_data.control_FDR_benjamini_hochberg(\n",
    "#     p_values_series_in=p_values_measures_df[\"MIC_p-value\"],\n",
    "#     alpha=0.05\n",
    "# )\n",
    "significant_p_values_dc_series, benjamini_hochberg_dc_data = cwatm_data.control_FDR_benjamini_hochberg(\n",
    "    p_values_series_in=p_values_measures_dc_df[\"MIC_p-value\"],\n",
    "    alpha=0.05\n",
    ")\n",
    "significant_p_values_dw_series, benjamini_hochberg_dw_data = cwatm_data.control_FDR_benjamini_hochberg(\n",
    "    p_values_series_in=p_values_measures_dw_df[\"MIC_p-value\"],\n",
    "    alpha=0.05\n",
    ")\n",
    "significant_p_values_wc_series, benjamini_hochberg_wc_data = cwatm_data.control_FDR_benjamini_hochberg(\n",
    "    p_values_series_in=p_values_measures_wc_df[\"MIC_p-value\"],\n",
    "    alpha=0.05\n",
    ")\n",
    "significant_p_values_ww_series, benjamini_hochberg_ww_data = cwatm_data.control_FDR_benjamini_hochberg(\n",
    "    p_values_series_in=p_values_measures_ww_df[\"MIC_p-value\"],\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "significant_p_values_ww_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benjamini_hochberg_results(bh_data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the sorted p-values\n",
    "    plt.plot(bh_data[\"data\"]['rank'], bh_data[\"data\"]['p_value'], marker='x', linestyle='none', label='P-values')\n",
    "    \n",
    "    # Plot the BH critical line\n",
    "    plt.plot(bh_data[\"data\"]['rank'], bh_data[\"data\"]['bh_critical_value'], color='red', label='BH Critical Value')\n",
    "    \n",
    "    # Add horizontal line at alpha level\n",
    "    plt.axhline(y=bh_data[\"alpha\"], color='grey', linestyle='--', label=f'Alpha = {bh_data[\"alpha\"]}')\n",
    "    \n",
    "    # Highlight significant points\n",
    "    significant_points = bh_data[\"data\"]['p_value'] <= bh_data['threshold_p_value']\n",
    "    print(sum(significant_points))\n",
    "    plt.scatter(bh_data[\"data\"]['rank'][significant_points],\n",
    "                bh_data[\"data\"]['p_value'][significant_points],\n",
    "                color='green',\n",
    "                label='Significant',\n",
    "                zorder=5)\n",
    "    \n",
    "    plt.xlabel('Rank of P-value')\n",
    "    plt.ylabel('P-value')\n",
    "    plt.title('Benjamini-Hochberg Procedure')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the results\n",
    "plot_benjamini_hochberg_results(benjamini_hochberg_ww_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"significant_p_values_series\" in locals():\n",
    "    significant_measures_df = measures_df[significant_p_values_series]\n",
    "else:\n",
    "    significant_measures_df = measures_df\n",
    "significant_measures_df = cwatm_data.compute_non_linearity(significant_measures_df)\n",
    "significant_ranks_measures_df = cwatm_data.compute_ranks_df(significant_measures_df)\n",
    "\n",
    "significant_measures_dc_df = measures_dc_df[significant_p_values_dc_series]\n",
    "significant_measures_dc_df = cwatm_data.compute_non_linearity(significant_measures_dc_df)\n",
    "significant_ranks_measures_dc_df = cwatm_data.compute_ranks_df(significant_measures_dc_df)\n",
    "\n",
    "significant_measures_dw_df = measures_dw_df[significant_p_values_dw_series]\n",
    "significant_measures_dw_df = cwatm_data.compute_non_linearity(significant_measures_dw_df)\n",
    "significant_ranks_measures_dw_df = cwatm_data.compute_ranks_df(significant_measures_dw_df)\n",
    "\n",
    "significant_measures_wc_df = measures_wc_df[significant_p_values_wc_series]\n",
    "significant_measures_wc_df = cwatm_data.compute_non_linearity(significant_measures_wc_df)\n",
    "significant_ranks_measures_wc_df = cwatm_data.compute_ranks_df(significant_measures_wc_df)\n",
    "\n",
    "significant_measures_ww_df = measures_ww_df[significant_p_values_ww_series]\n",
    "significant_measures_ww_df = cwatm_data.compute_non_linearity(significant_measures_ww_df)\n",
    "significant_ranks_measures_ww_df = cwatm_data.compute_ranks_df(significant_measures_ww_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "top_10percent_table_dc_df = significant_measures_dc_df.join([significant_ranks_measures_dc_df, p_values_measures_dc_df],\n",
    "                                                            how=\"left\")\n",
    "\n",
    "top_10percent_table_dc_df = top_10percent_table_dc_df[[\"pearson\",   \"pearson_rank\",  # \"pearson_p-value\",  \n",
    "                                                    \"spearman\",  \"spearman_rank\", # \"spearman_p-value\",\n",
    "                                                    \"MIC\",       \"MIC_rank\",      # \"MIC_p-value\",\n",
    "                                                    \"MAS\",       \"MAS_rank\",      # \"MAS_p-value\",\n",
    "                                                    \"MEV\",       \"MEV_rank\",      # \"MEV_p-value\",\n",
    "                                                    \"MIC - p^2\", \"MIC - p^2_rank\"\n",
    "                                                    ]]\n",
    "\n",
    "top_10percent_table_dc_df = top_10percent_table_dc_df.convert_dtypes()\n",
    "\n",
    "top_10percent_table_dc_df.sort_values(\"MIC\", ascending=False).head(n=int(0.1 * len(top_10percent_table_dc_df))).round(3).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_top_n_inputs_by_measure_for_each_output(input_df: pd.DataFrame,\n",
    "                                                 top_n: int = 6,\n",
    "                                                 with_value: bool = True):\n",
    "    \n",
    "    outputs = [\"evap-total\", \"potevap\", \"tws\", \"qtot\", \"qr\"]\n",
    "    stats = [\"pearson\", \"spearman\", \"MIC\"]\n",
    "    if with_value:\n",
    "        subcols = [\"input\", \"value\"]\n",
    "    else:\n",
    "        subcols = [\"input\"]\n",
    "\n",
    "    ind_tuples = [(output, rank + 1) for output in outputs for rank in range(top_n)]\n",
    "    index = pd.MultiIndex.from_tuples(ind_tuples, names=[\"output\", \"rank\"])\n",
    "\n",
    "    col_tuples = [(stat, subcol) for stat in stats for subcol in subcols]\n",
    "    columns = pd.MultiIndex.from_tuples(col_tuples, names=[\"measure\", \"subcol\"])\n",
    "\n",
    "    result_df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    temp_df = input_df.copy()\n",
    "\n",
    "    for output in outputs:\n",
    "        df_output = temp_df.xs(output, level='output')\n",
    "        for stat in stats:\n",
    "            df_stat_sorted = df_output.sort_values(by=stat, ascending=False)\n",
    "            top = df_stat_sorted.iloc[:top_n]\n",
    "            inputs = top.index.values\n",
    "            values = top[stat].values\n",
    "            for i, (input_var, value) in enumerate(zip(inputs, values)):\n",
    "                rank = i + 1\n",
    "                result_df.loc[(output, rank), (stat, \"input\")] = input_var\n",
    "                if with_value:\n",
    "                    result_df.loc[(output, rank), (stat, \"value\")] = np.round(value, 2)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "top_inputs_by_measure_for_each_output = make_top_n_inputs_by_measure_for_each_output(\n",
    "    significant_measures_df,\n",
    "    with_value=False\n",
    ")\n",
    "\n",
    "top_inputs_by_measure_for_each_output.to_csv(\n",
    "    \"../data/processed/bivariate_metrics/CWatM/summary_tables/top_inputs_by_measure_for_each_output.csv\"\n",
    ")\n",
    "dfi.export(top_inputs_by_measure_for_each_output,\n",
    "           \"../reports/tables/CWatM_data/top_inputs_by_measure_for_each_output_global.png\",\n",
    "           table_conversion=\"matplotlib\", dpi=300)\n",
    "\n",
    "display(top_inputs_by_measure_for_each_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_top_n_inputs_by_measure_for_each_output_with_regions(global_df: pd.DataFrame,\n",
    "                                                              region_dc_df: pd.DataFrame,\n",
    "                                                              region_dw_df: pd.DataFrame,\n",
    "                                                              region_wc_df: pd.DataFrame,\n",
    "                                                              region_ww_df: pd.DataFrame,\n",
    "                                                              top_n: int = 6,\n",
    "                                                              with_value: bool = True):\n",
    "    \n",
    "    table_global = make_top_n_inputs_by_measure_for_each_output(global_df, top_n=top_n, with_value=with_value)\n",
    "    table_dc = make_top_n_inputs_by_measure_for_each_output(region_dc_df, top_n=top_n, with_value=with_value)\n",
    "    table_dw = make_top_n_inputs_by_measure_for_each_output(region_dw_df, top_n=top_n, with_value=with_value)\n",
    "    table_wc = make_top_n_inputs_by_measure_for_each_output(region_wc_df, top_n=top_n, with_value=with_value)\n",
    "    table_ww = make_top_n_inputs_by_measure_for_each_output(region_ww_df, top_n=top_n, with_value=with_value)\n",
    "\n",
    "    table_global = pd.concat([table_global], keys=[\"global\"], names=[\"region\"], axis=1)\n",
    "    table_dc = pd.concat([table_dc], keys=[\"dry cold\"], names=[\"region\"], axis=1)\n",
    "    table_dw = pd.concat([table_dw], keys=[\"dry warm\"], names=[\"region\"], axis=1)\n",
    "    table_wc = pd.concat([table_wc], keys=[\"wet cold\"], names=[\"region\"], axis=1)\n",
    "    table_ww = pd.concat([table_ww], keys=[\"wet warm\"], names=[\"region\"], axis=1)\n",
    "\n",
    "    table_all = table_global.join([table_dc, table_dw, table_wc, table_ww])\n",
    "\n",
    "    table_all = table_all.reorder_levels([\"measure\", \"region\", \"subcol\"], axis=\"columns\").sort_index(axis=\"columns\", level=\"measure\")\n",
    "    table_all = table_all.reindex(columns=[\"pearson\", \"spearman\", \"MIC\"], level=\"measure\")\n",
    "    table_all = table_all.reindex(columns=[\"global\", \"dry cold\", \"dry warm\", \"wet cold\", \"wet warm\"], level=\"region\")\n",
    "\n",
    "    return table_all\n",
    "\n",
    "top_inputs_by_measure_for_each_output_with_regions_and_value = make_top_n_inputs_by_measure_for_each_output_with_regions(\n",
    "    significant_measures_df,\n",
    "    significant_measures_dc_df,\n",
    "    significant_measures_dw_df,\n",
    "    significant_measures_wc_df,\n",
    "    significant_measures_ww_df,\n",
    "    top_n=6,\n",
    "    with_value=True\n",
    ")\n",
    "\n",
    "top_inputs_by_measure_for_each_output_with_regions = make_top_n_inputs_by_measure_for_each_output_with_regions(\n",
    "    significant_measures_df,\n",
    "    significant_measures_dc_df,\n",
    "    significant_measures_dw_df,\n",
    "    significant_measures_wc_df,\n",
    "    significant_measures_ww_df,\n",
    "    top_n=6,\n",
    "    with_value=False\n",
    ")\n",
    "\n",
    "top_inputs_by_measure_for_each_output_with_regions_and_value.to_csv(\n",
    "    \"../data/processed/bivariate_metrics/CWatM/summary_tables/top_inputs_by_measure_for_each_output_with_regions_and_value.csv\"\n",
    ")\n",
    "dfi.export(top_inputs_by_measure_for_each_output_with_regions_and_value,\n",
    "           \"../reports/tables/CWatM_data/top_inputs_by_measure_for_each_output_with_regions_and_value.png\",\n",
    "           table_conversion=\"matplotlib\", dpi=300)\n",
    "\n",
    "top_inputs_by_measure_for_each_output_with_regions.to_csv(\n",
    "    \"../data/processed/bivariate_metrics/CWatM/summary_tables/top_inputs_by_measure_for_each_output_with_regions.csv\"\n",
    ")\n",
    "dfi.export(top_inputs_by_measure_for_each_output_with_regions, \n",
    "           \"../reports/tables/CWatM_data/top_inputs_by_measure_for_each_output_with_regions.png\",\n",
    "           table_conversion=\"matplotlib\", dpi=300)\n",
    "\n",
    "display(top_inputs_by_measure_for_each_output_with_regions_and_value)\n",
    "display(top_inputs_by_measure_for_each_output_with_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_global, table_dc, table_dw, table_wc, table_ww = top_inputs_by_measure_for_each_output_with_regions_and_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_global.join([table_dc, table_dw, table_wc, table_ww])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix(input_df):\n",
    "    temp_df = input_df.copy()\n",
    "    temp_df[\"pearson\"] = temp_df[\"pearson\"]**2\n",
    "    temp_df[\"spearman\"] = temp_df[\"spearman\"]**2\n",
    "    pearson_corr_matrix = temp_df.corr(method=\"pearson\").round(2)\n",
    "    fig = px.imshow(pearson_corr_matrix, text_auto=True, zmin=-1, zmax=+1)\n",
    "    fig.show()\n",
    "\n",
    "plot_corr_matrix(significant_measures_df)\n",
    "plot_corr_matrix(significant_measures_dc_df)\n",
    "plot_corr_matrix(significant_measures_dw_df)\n",
    "plot_corr_matrix(significant_measures_wc_df)\n",
    "plot_corr_matrix(significant_measures_ww_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_matrix(input_df):\n",
    "    temp_df = input_df.copy()\n",
    "    fig = go.Figure(\n",
    "        data=go.Splom(\n",
    "            dimensions=[dict(label=col,\n",
    "                             values=temp_df[col]) for col in temp_df.columns],\n",
    "        diagonal_visible=False, # remove plots on diagonal\n",
    "        # showupperhalf=False,\n",
    "        text=measures_df.index.to_list(),\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title='Measures of dependence',\n",
    "        width=900,\n",
    "        height=600,\n",
    "        hovermode=\"x\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_scatter_matrix(significant_measures_df)\n",
    "plot_scatter_matrix(significant_measures_dc_df)\n",
    "plot_scatter_matrix(significant_measures_dw_df)\n",
    "plot_scatter_matrix(significant_measures_wc_df)\n",
    "plot_scatter_matrix(significant_measures_ww_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_measures_df.loc[(\"albedoWater\", \"potevap\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values_and_rank(input_df,\n",
    "                         region,\n",
    "                         n_top = 20):\n",
    "    temp_df = input_df.copy()\n",
    "    fig = visualize.plot_measure_values_and_rank(\n",
    "        measures_df=temp_df,\n",
    "        # measures=[\"pearson\", \"spearman\", \"mutual information (sklearn)\", \"normalized mutual information\", \"MIC\"],\n",
    "        # measures=[\"pearson\", \"spearman\", \"normalized mutual information\", \"MIC\"],\n",
    "        # measures=[\"pearson\", \"spearman\", \"MIC\"],\n",
    "        measures=[\"pearson\", \"spearman\", \"MIC\", \"MIC - p^2\", \"MAS\"],\n",
    "        sort_values_by=\"MIC\",\n",
    "        n_top=n_top\n",
    "    )\n",
    "    fig.suptitle(region)\n",
    "\n",
    "plot_values_and_rank(significant_measures_df, region=\"global\")\n",
    "plot_values_and_rank(significant_measures_dc_df, region=\"dry cold\")\n",
    "plot_values_and_rank(significant_measures_dw_df, region=\"dry warm\")\n",
    "plot_values_and_rank(significant_measures_wc_df, region=\"wet cold\")\n",
    "plot_values_and_rank(significant_measures_ww_df, region=\"wet warm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# # Create a 3D scatter plot\n",
    "# fig = px.scatter_3d(\n",
    "#     measures_df.abs(),\n",
    "#     x=\"MIC\",\n",
    "#     y=\"pearson\",\n",
    "#     z=\"spearman\",\n",
    "#     color=\"MCN_general\",\n",
    "#     title=\"MIC metrics\",\n",
    "#     opacity=0.7\n",
    "# )\n",
    "# fig.show()\n",
    "# # # Show the plot\n",
    "# # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# MEASURE = \"MIC\"\n",
    "# IMAGES_FOLDER = Path(\"../reports/figures/CWatM_data/scatterplots\")\n",
    "\n",
    "# X = measures_df.abs().dropna()\n",
    "\n",
    "# low_threshold = np.percentile(X[MEASURE], q=90)\n",
    "# upp_threshold = np.percentile(X[MEASURE], q=100)\n",
    "\n",
    "# top_df = X[(X[MEASURE] >= low_threshold) & (X[MEASURE] <= upp_threshold)]\n",
    "\n",
    "# top_df = X[(X[\"MIC\"] >= low_threshold) & (X[\"MIC\"] <= upp_threshold)]\n",
    "\n",
    "# print(f\"Number of samples meeting the condition: {len(top_df)} out of {len(X)}\")\n",
    "\n",
    "# image_filenames = [f\"{pairs[0]}_{pairs[1]}.png\" for pairs in top_df.sample(n=20).index.to_list()]\n",
    "# image_filenames = [IMAGES_FOLDER.joinpath(f) for f in image_filenames]\n",
    "\n",
    "# # Create a figure and subplots\n",
    "# fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(12, 8))\n",
    "\n",
    "# # Flatten the axes array for easy iteration\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# # Loop through images and display them\n",
    "# for idx, ax in enumerate(axes):\n",
    "#     if idx < len(image_filenames):\n",
    "#         # Check if file exists\n",
    "#         if os.path.exists(image_filenames[idx]):\n",
    "#             # Read and display image\n",
    "#             img = mpimg.imread(image_filenames[idx], format=\"png\")\n",
    "#             ax.imshow(img)\n",
    "#             ax.axis('off')  # Hide axes ticks\n",
    "#             ax.set_title(f'Image {idx+1}')\n",
    "#         else:\n",
    "#             ax.text(0.5, 0.5, 'Image not found', fontsize=12, ha='center')\n",
    "#             ax.axis('off')\n",
    "#     else:\n",
    "#         # Hide any extra subplots if fewer images\n",
    "#         ax.axis('off')\n",
    "\n",
    "# # Adjust spacing between subplots\n",
    "# fig.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# MEASURE = \"MIC\"\n",
    "# IMAGES_FOLDER = Path(\"../reports/figures/CWatM_data/scatterplots\")\n",
    "\n",
    "# X = measures_df.abs().dropna()\n",
    "\n",
    "# low_threshold = np.percentile(X[MEASURE], q=90)\n",
    "# upp_threshold = np.percentile(X[MEASURE], q=100)\n",
    "\n",
    "# top_df = X[(X[MEASURE] >= low_threshold) & (X[MEASURE] <= upp_threshold)]\n",
    "\n",
    "# print(f\"Number of samples meeting the condition: {len(top_df)} out of {len(X)}\")\n",
    "\n",
    "# # Number of samples to display\n",
    "# top_n = 10  # Adjust this number based on how many images you want per column\n",
    "\n",
    "# # 1. Sample top_n samples\n",
    "# top_df_sorted_by_MIC = top_df.sample(n=top_n, random_state=21)\n",
    "\n",
    "# def get_image_filenames(df):\n",
    "#     image_filenames = [f\"{pairs[0]}_{pairs[1]}.png\" for pairs in df.index.to_list()]\n",
    "#     image_filenames = [IMAGES_FOLDER.joinpath(f) for f in image_filenames]\n",
    "#     return image_filenames\n",
    "\n",
    "# # 3. Sort the images according to each column\n",
    "# # Since we want the same images in each column but sorted differently, we sort 'top_df_sorted_by_MIC' by different columns\n",
    "# images_sorted_by_pearson = top_df_sorted_by_MIC.sort_values(by='pearson', ascending=False)\n",
    "# images_sorted_by_spearman = top_df_sorted_by_MIC.sort_values(by='spearman', ascending=False)\n",
    "# images_sorted_by_MIC = top_df_sorted_by_MIC.sort_values(by='MIC', ascending=False)\n",
    "# images_sorted_by_MEV = top_df_sorted_by_MIC.sort_values(by='MEV', ascending=False)\n",
    "# images_sorted_by_MAS = top_df_sorted_by_MIC.sort_values(by='MAS', ascending=False)\n",
    "# images_sorted_by_MCN = top_df_sorted_by_MIC.sort_values(by='MCN_general', ascending=False)\n",
    "\n",
    "# # Get image filenames for each sorting\n",
    "# image_filenames_pearson = get_image_filenames(images_sorted_by_pearson)\n",
    "# image_filenames_spearman = get_image_filenames(images_sorted_by_spearman)\n",
    "# image_filenames_MIC = get_image_filenames(images_sorted_by_MIC)\n",
    "# image_filenames_MEV = get_image_filenames(images_sorted_by_MEV)\n",
    "# image_filenames_MAS = get_image_filenames(images_sorted_by_MAS)\n",
    "# image_filenames_MCN = get_image_filenames(images_sorted_by_MCN)\n",
    "\n",
    "# # 4. Plot the images in a subplot grid\n",
    "\n",
    "# # Number of rows and columns\n",
    "# nrows = top_n\n",
    "# ncols = 6\n",
    "\n",
    "# # Create a figure and subplots\n",
    "# fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, nrows * 1))\n",
    "\n",
    "# # If axes is a 1D array when nrows=1 or ncols=1, make it 2D for consistent indexing\n",
    "# if nrows == 1 or ncols == 1:\n",
    "#     axes = axes.reshape(nrows, ncols)\n",
    "\n",
    "# # List of image filenames sorted by each column\n",
    "# sorted_images = [image_filenames_pearson, image_filenames_spearman, image_filenames_MIC, image_filenames_MEV, image_filenames_MAS, image_filenames_MCN]\n",
    "# column_titles = ['Sorted by pearson', 'Sorted by spearman', 'Sorted by MIC', 'Sorted by MEV', 'Sorted by MAS', \"Sorted by MCN\"]\n",
    "\n",
    "# # Loop through columns and rows to display images\n",
    "# for col in range(ncols):\n",
    "#     images = sorted_images[col]\n",
    "#     for row in range(nrows):\n",
    "#         ax = axes[row, col]\n",
    "#         img_path = images[row]\n",
    "#         if os.path.exists(img_path):\n",
    "#             img = mpimg.imread(img_path)\n",
    "#             ax.imshow(img)\n",
    "#             ax.axis('off')  # Hide axes ticks\n",
    "#             # Optionally, add image title or value\n",
    "#             # ax.set_title(f'Image {row+1}')\n",
    "#         else:\n",
    "#             ax.text(0.5, 0.5, 'Image not found', fontsize=12, ha='center')\n",
    "#             ax.axis('off')\n",
    "#     # Set the column title\n",
    "#     axes[0, col].set_title(column_titles[col], fontsize=16)\n",
    "\n",
    "# # Adjust spacing between subplots\n",
    "# fig.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURES = [\n",
    "#     \"pearson\",\n",
    "#     \"spearman\",\n",
    "#     \"MIC\",\n",
    "#     \"MAS\",\n",
    "#     \"MEV\",\n",
    "#     \"MCN_general\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.cluster import KMeans, DBSCAN\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "\n",
    "# range_n_clusters = [2, 3, 4, 5]\n",
    "\n",
    "# X = measures_df[MEASURES].dropna().abs().to_numpy()\n",
    "\n",
    "# for n_clusters in range_n_clusters:\n",
    "#     # Create a subplot with 1 row and 2 columns\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "#     fig.set_size_inches(18, 7)\n",
    "\n",
    "#     # The 1st subplot is the silhouette plot\n",
    "#     # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "#     # lie within [-0.1, 1]\n",
    "#     ax1.set_xlim([-0.1, 1])\n",
    "#     # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "#     # plots of individual clusters, to demarcate them clearly.\n",
    "#     ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "#     # Initialize the clusterer with n_clusters value and a random generator\n",
    "#     # seed of 10 for reproducibility.\n",
    "#     clusterer = KMeans(n_clusters=n_clusters, init=\"k-means++\", random_state=23)\n",
    "#     # clusterer = DBSCAN()\n",
    "\n",
    "#     cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "#     # The silhouette_score gives the average value for all the samples.\n",
    "#     # This gives a perspective into the density and separation of the formed\n",
    "#     # clusters\n",
    "#     silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "#     print(\n",
    "#         \"For n_clusters =\",\n",
    "#         n_clusters,\n",
    "#         \"The average silhouette_score is :\",\n",
    "#         silhouette_avg,\n",
    "#     )\n",
    "\n",
    "#     # Compute the silhouette scores for each sample\n",
    "#     sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "#     y_lower = 10\n",
    "#     for i in range(n_clusters):\n",
    "#         # Aggregate the silhouette scores for samples belonging to\n",
    "#         # cluster i, and sort them\n",
    "#         ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "#         ith_cluster_silhouette_values.sort()\n",
    "\n",
    "#         size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "#         y_upper = y_lower + size_cluster_i\n",
    "\n",
    "#         color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "#         ax1.fill_betweenx(\n",
    "#             np.arange(y_lower, y_upper),\n",
    "#             0,\n",
    "#             ith_cluster_silhouette_values,\n",
    "#             facecolor=color,\n",
    "#             edgecolor=color,\n",
    "#             alpha=0.7,\n",
    "#         )\n",
    "\n",
    "#         # Label the silhouette plots with their cluster numbers at the middle\n",
    "#         ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "#         # Compute the new y_lower for next plot\n",
    "#         y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "#     ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "#     ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "#     ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "#     # The vertical line for average silhouette score of all the values\n",
    "#     ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "#     ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "#     ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "#     # # 2nd Plot showing the actual clusters formed\n",
    "#     # colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "#     # ax2.scatter(\n",
    "#     #     X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "#     # )\n",
    "\n",
    "#     # Labeling the clusters\n",
    "#     centers = clusterer.cluster_centers_\n",
    "#     # Draw white circles at cluster centers\n",
    "#     ax2.scatter(\n",
    "#         centers[:, 0],\n",
    "#         centers[:, 1],\n",
    "#         marker=\"o\",\n",
    "#         c=\"white\",\n",
    "#         alpha=1,\n",
    "#         s=200,\n",
    "#         edgecolor=\"k\",\n",
    "#     )\n",
    "\n",
    "#     for i, c in enumerate(centers):\n",
    "#         ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "#     ax2.set_title(\"The visualization of the clustered data.\")\n",
    "#     ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "#     ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "#     plt.suptitle(\n",
    "#         \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
    "#         % n_clusters,\n",
    "#         fontsize=14,\n",
    "#         fontweight=\"bold\",\n",
    "#     )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURES = [\n",
    "#     # \"pearson\",\n",
    "#     # \"spearman\",\n",
    "#     # \"mutual information (sklearn)\",\n",
    "#     # \"normalized mutual information\",\n",
    "#     \"MIC\",\n",
    "#     \"MEV\",\n",
    "#     \"MAS\",\n",
    "#     \"MCN_general\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# X = measures_df[MEASURES].dropna()\n",
    "\n",
    "# # Initialize t-SNE with desired parameters\n",
    "# tsne = TSNE(n_components=3,        # Reduce to 3 dimensions for visualization\n",
    "#             perplexity=20,         # Controls the balance between local and global aspects of the data\n",
    "#             early_exaggeration=12, \n",
    "#             n_iter=1000,           # Number of iterations for optimization\n",
    "#             random_state=23)\n",
    "\n",
    "# # Fit and transform the data\n",
    "# X_embedded = tsne.fit_transform(X)\n",
    "\n",
    "# # Visualize\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# scatter = plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=X_embedded[:, 2], cmap='viridis', alpha=0.7)\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "# plt.title(\"t-SNE Visualization of High-Dimensional Data\")\n",
    "# plt.xlabel(\"t-SNE Feature 1\")\n",
    "# plt.ylabel(\"t-SNE Feature 2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis-U6WNLqtN-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
